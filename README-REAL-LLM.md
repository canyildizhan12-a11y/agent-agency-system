# üß† REAL LLM MULTI-AGENT SYSTEM

**How to run ACTUAL Kimi K2.5 sub-agents using sessions_spawn**

---

## The Problem

The previous implementation used **templates** - pre-written responses that simulate what agents would say. This is NOT real AI.

## The Solution

Use OpenClaw's `sessions_spawn` tool to create **REAL** sub-agent sessions, each running Kimi K2.5 with their own expert persona.

---

## How It Actually Works

```
Main Agent (You/Garmin)
         ‚Üì
    sessions_spawn (Tool Call)
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Sub-Agent 1: Henry (Kimi K2.5 + Henry System Prompt)   ‚îÇ
    ‚îÇ  Sub-Agent 2: Scout (Kimi K2.5 + Scout System Prompt)   ‚îÇ
    ‚îÇ  Sub-Agent 3: Pixel (Kimi K2.5 + Pixel System Prompt)   ‚îÇ
    ‚îÇ  Sub-Agent 4: Echo  (Kimi K2.5 + Echo System Prompt)    ‚îÇ
    ‚îÇ  Sub-Agent 5: Quill (Kimi K2.5 + Quill System Prompt)   ‚îÇ
    ‚îÇ  Sub-Agent 6: Codex (Kimi K2.5 + Codex System Prompt)   ‚îÇ
    ‚îÇ  Sub-Agent 7: Alex  (Kimi K2.5 + Alex System Prompt)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Collect Real LLM Responses
         ‚Üì
    Continue Meeting
```

Each sub-agent is a **separate Kimi K2.5 session** with:
- Unique system prompt (persona, expertise, traits)
- Isolated context
- Real intelligent responses
- No template garbage

---

## Step-by-Step Implementation

### Step 1: Generate Agent Prompts

```javascript
const { generateMeetingPrompts } = require('./agent-prompts');

// Get prompts for all 7 agents
const prompts = generateMeetingPrompts('Competitor Analysis');

// prompts.henry = Henry's full system prompt + meeting context
// prompts.scout = Scout's full system prompt + meeting context
// etc.
```

### Step 2: Spawn REAL Sub-Agents

**FOR EACH AGENT, CALL:**

```javascript
// Tool call: sessions_spawn
{
  "task": prompts.henry,  // Full system prompt + meeting context
  "model": "kimi-coding/k2p5",
  "timeoutSeconds": 60,
  "label": "meeting-henry-round1"
}
```

**DO THIS 7 TIMES (once per agent):**
- `sessions_spawn` with `prompts.henry`
- `sessions_spawn` with `prompts.scout`
- `sessions_spawn` with `prompts.pixel`
- `sessions_spawn` with `prompts.echo`
- `sessions_spawn` with `prompts.quill`
- `sessions_spawn` with `prompts.codex`
- `sessions_spawn` with `prompts.alex`

### Step 3: Collect Real Responses

Each sub-agent returns a **REAL** response generated by Kimi K2.5:
- Henry might say: "ü¶â Good morning team! I've been analyzing our strategic position..."
- Scout might say: "üîç I found something interesting! CompetitorX just launched..."
- etc.

**These are NOT templates - they're actual LLM outputs.**

### Step 4: Continue Meeting

Take the real responses from Round 1, add to context, spawn Round 2.

---

## For The Main Agent (Garmin)

### Run a Real Meeting NOW:

1. **Read the prompts:**
   ```bash
   node run-real-meeting.js
   ```
   This shows you the exact prompts for each agent.

2. **Spawn 7 sub-agents using sessions_spawn tool:**
   ```javascript
   // For Henry
   sessions_spawn({
     task: prompts.henry,
     model: 'kimi-coding/k2p5',
     timeoutSeconds: 60
   });
   
   // For Scout
   sessions_spawn({
     task: prompts.scout,
     model: 'kimi-coding/k2p5',
     timeoutSeconds: 60
   });
   
   // ... repeat for all 7 agents
   ```

3. **Wait for all 7 responses**

4. **Continue to Round 2** with collected responses

5. **Repeat until meeting complete**

---

## Cost Considerations

### Template System (Previous):
- **Cost:** $0 (no LLM calls)
- **Intelligence:** None (fake responses)

### Real LLM System (This):
- **Cost:** ~7 agents √ó 2 rounds √ó ~500 tokens = ~7,000 tokens per meeting
- **Intelligence:** ACTUAL Kimi K2.5 reasoning

### Recommendation:
- Use **real LLM** for important meetings
- Use **templates** for testing/low-stakes scenarios
- **Sleep/wake cycle** keeps costs down (agents only active during meetings)

---

## Agent Personas

Each agent has a **detailed system prompt** including:

| Agent | Expertise | Traits |
|-------|-----------|--------|
| **Henry** ü¶â | Planning, Leadership | Leadership 9/10, Social 8/10 |
| **Scout** üîç | Research, Intelligence | Analytical 9/10, Technical 5/10 |
| **Pixel** üé® | Creative, Visual | Creativity 10/10, Analytical 4/10 |
| **Echo** üíª | Development, Code | Technical 10/10, Social 4/10 |
| **Quill** ‚úçÔ∏è | Writing, Content | Creativity 9/10, Social 8/10 |
| **Codex** üèóÔ∏è | Architecture, Systems | Technical 9/10, Analytical 9/10 |
| **Alex** üìä | Analytics, Data | Analytical 10/10, Technical 7/10 |

Each prompt includes:
- Full personality description
- Communication style
- Strengths and weaknesses
- Critical rules (stay in character, use emoji, etc.)

---

## Example Real Response

**Topic:** Competitor Analysis

**Henry's REAL response (via sessions_spawn):**
> ü¶â Good morning team! I've been reviewing our competitive landscape, and I see both opportunities and threats. Our differentiation in AI transparency is solid, but we're falling behind on feature velocity. Scout, what are you seeing in the market?

**Scout's REAL response (via sessions_spawn):**
> üîç I've been monitoring this closely! CompetitorX launched their automation suite last Tuesday - 62% positive reception on Twitter, but Reddit threads show complaints about reliability. Here's the gap: none of them are addressing the "fail fast, learn faster" narrative that our audience resonates with. Opportunity!

**These are dynamically generated by Kimi K2.5, not templates.**

---

## Quick Start

### Option 1: Run with Real LLM (RECOMMENDED)

```bash
# Generate meeting prompts
node run-real-meeting.js

# Then, as the main agent, use sessions_spawn tool
# to spawn 7 sub-agents with those prompts
```

### Option 2: Continue with Templates (TESTING)

```bash
# Use the simulation system
node real-orchestrator.js meeting
```

---

## Implementation Checklist

- [x] Agent personas defined
- [x] System prompts created
- [x] Meeting flow designed
- [ ] **YOU NEED TO:** Call sessions_spawn for each agent
- [ ] **YOU NEED TO:** Collect real LLM responses
- [ ] **YOU NEED TO:** Continue meeting rounds

---

## The Bottom Line

**Template System:** Fake, predictable, free  
**Real LLM System:** Intelligent, creative, costs tokens

**For a REAL autonomous agent agency:** Use sessions_spawn + Kimi K2.5

**For testing/demo:** Templates are fine

---

**Ready to run real agents?** Generate prompts with `node run-real-meeting.js` then spawn them with `sessions_spawn`.
